{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import MinHashLSH\n",
    "\n",
    "csv_name = 'spotify_dataset_top10000.csv'\n",
    "\n",
    "\n",
    "os.environ['JAVA_HOME'] = r\"C:\\Program Files\\Java\\jdk-15.0.1\" \n",
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"10g\").getOrCreate()\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").schema('playlist_id integer, track_id integer').csv(csv_name).na.drop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = df.select(\"playlist_id\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit,concat,col\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from time import time\n",
    "\n",
    "def encode(arr, length):\n",
    "    arr = list(set(arr))    \n",
    "    return Vectors.sparse(length, [(x,1.0) for x in arr]) \n",
    "\n",
    "vecs = df.groupBy('track_id').agg(F.collect_list(\"playlist_id\").alias(\"vec\")).sort('track_id')\\\n",
    "    .withColumn('sparse', F.udf(encode, VectorUDT())(F.col(\"vec\"),F.lit(max_len)))\\\n",
    "    .select('track_id','sparse').cache()\n",
    "\n",
    "\n",
    "mh = MinHashLSH(inputCol=\"sparse\", outputCol=\"hashes\",numHashTables = 20)\n",
    "model = mh.fit(vecs)\n",
    "transformed = model.transform(vecs).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "#Perform approximate similartiy join to find similar songs\n",
    "\n",
    "sim = model.approxSimilarityJoin(transformed, transformed,1).filter('DatasetA.track_id <> DatasetB.track_id')\n",
    "\n",
    "w = Window.partitionBy(\"datasetA.track_id\").orderBy(\"distCol\")\n",
    "rec = sim.filter('DatasetA.track_id <> DatasetB.track_id')\\\n",
    ".withColumn(\"rn\", F.row_number().over(w)).where(F.col(\"rn\") == 1).drop(\"rn\").collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(min(count)=31)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check minimum number of reccomendations per \n",
    "sim.groupby('DatasetA.track_id').count().agg(F.min(F.col('count'))).collect()\n",
    "sim.filter('DatasetA.track_id <> DatasetB.track_id').select(sim.datasetA.track_id).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Skrillex-Bangarang (feat. Sirah)</td>\n",
       "      <td>Skrillex-Kyoto (feat. Sirah)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>Maia Wilson-Fixer Upper</td>\n",
       "      <td>Josh Gad-In Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>Ed Sheeran-Small Bump</td>\n",
       "      <td>Ed Sheeran-U.N.I.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Coldplay-Fix You</td>\n",
       "      <td>Coldplay-The Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>Azealia Banks-212</td>\n",
       "      <td>Azealia Banks-1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7874</th>\n",
       "      <td>Jason Mraz-A Beautiful Mess</td>\n",
       "      <td>Jason Mraz-Make It Mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>Friendly Fires-Paris</td>\n",
       "      <td>Friendly Fires-Jump In The Pool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>Weezer-El Scorcho</td>\n",
       "      <td>Weezer-The Good Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9067</th>\n",
       "      <td>Massive Attack-Paradise Circus - Gui Boratto R...</td>\n",
       "      <td>Massive Attack-Girl I Love You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9901</th>\n",
       "      <td>Lauryn Hill-Can't Take My Eyes Off Of You</td>\n",
       "      <td>Lauryn Hill-Everything Is Everything</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      track  \\\n",
       "track_id                                                      \n",
       "148                        Skrillex-Bangarang (feat. Sirah)   \n",
       "463                                 Maia Wilson-Fixer Upper   \n",
       "471                                   Ed Sheeran-Small Bump   \n",
       "496                                        Coldplay-Fix You   \n",
       "833                                       Azealia Banks-212   \n",
       "...                                                     ...   \n",
       "7874                            Jason Mraz-A Beautiful Mess   \n",
       "7999                                   Friendly Fires-Paris   \n",
       "8054                                      Weezer-El Scorcho   \n",
       "9067      Massive Attack-Paradise Circus - Gui Boratto R...   \n",
       "9901              Lauryn Hill-Can't Take My Eyes Off Of You   \n",
       "\n",
       "                                           rec  \n",
       "track_id                                        \n",
       "148               Skrillex-Kyoto (feat. Sirah)  \n",
       "463                         Josh Gad-In Summer  \n",
       "471                          Ed Sheeran-U.N.I.  \n",
       "496                     Coldplay-The Scientist  \n",
       "833                         Azealia Banks-1991  \n",
       "...                                        ...  \n",
       "7874                   Jason Mraz-Make It Mine  \n",
       "7999           Friendly Fires-Jump In The Pool  \n",
       "8054                      Weezer-The Good Life  \n",
       "9067            Massive Attack-Girl I Love You  \n",
       "9901      Lauryn Hill-Everything Is Everything  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_ids = [[r[0][0],r[1][0]] for r in rec]\n",
    "df_rec = pd.DataFrame(rec_ids)\n",
    "df_rec.columns = ['track','rec']\n",
    "\n",
    "with open('name_to_id.json', 'rb') as d:\n",
    "    name_to_id = json.load(d)\n",
    "    id_to_name = {v:k for k,v in name_to_id.items()}\n",
    "\n",
    "df_rec.index = df_rec.track\n",
    "df_rec = df_rec.applymap(lambda x: id_to_name[x])\n",
    "df_rec.index.name = 'track_id'\n",
    "df_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "near \"IF\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-3b1de14d1443>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DROP IF EXISTS TABLE top_one\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf_rec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'top_one'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: near \"IF\": syntax error"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('reccomendations.db')\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"DROP IF EXISTS TABLE top_one\")\n",
    "\n",
    "df_rec.to_sql('top_one',conn)\n",
    "\n",
    "# Save (commit) the changes\n",
    "conn.commit()\n",
    "\n",
    "# We can also close the connection if we are done with it.\n",
    "# Just be sure any changes have been committed or they will be lost.\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
